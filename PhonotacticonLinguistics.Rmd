---
title: "R Markdown script used for ``Phonological distances between Eurasian lects measured
via Phonotacticon 1.0 reveal areal patterns''"
date: "23 June 2025"
author: "Ian Joo and Yu-Yin Hsu"
output:
  pdf_document: 
    latex_engine: xelatex
  html_document:
    df_print: paged
header-includes:
- \pagenumbering{gobble}
- \usepackage{fontspec}
- \setmainfont{Times New Roman}
- \setmonofont{Arial Unicode MS}
fontsize: 12pt
geometry: 'margin = 2.5cm'
papersize: a4
---

# Data

Set up the environment of R Markdown.

```{r Setup}
options(scipen = 100, digits = 3)
options(datatable.print.nrows = 5,
        datatable.print.trunc.cols = T)
```

Load the required R packages.

```{r Libraries, message = FALSE}
library(data.table)
library(tidytable)
library(stringr)
library(stringi)
library(geosphere)
library(plotly)
library(geodata)
library(plyr)
library(tibble)
library(forcats)
library(purrr)
library(Rfast)
library(e1071)
library(caret)
library(dplyr)
library(anocva)
library(profmem)
library(stargazer)
library(lme4)
library(viridis)
library(spdep)
library(spatialreg)
library(xtable)
library(ggforce)
library(magrittr)
library(vegan)
library(parallel)
library(doParallel)
library(parallelDist)
library(cluster)
library(ggdendro)
library(ggrepel)
```

Load Phonotacticon.

```{r Phonotacticon}
Phonotacticon <- fread("Phonotacticon1_0.csv") %>% 
  as.data.table()

Phonotacticon
```

All the subset sample lects are listed below.

```{r Eurasia}
Eurasia <- Phonotacticon %>% 
  .[Onset != '?' & 
    Nucleus != '?' &
    Coda != '?' &
    !grepl('C{2,}', Onset) &
    !grepl('C{2,}', Coda) &
    !grepl('\\[.{10}.*?\\]\\[.{10}.*?\\]', Onset) &
    !grepl('\\[.{10}.*?\\]\\[.{10}.*?\\]', Coda),
  .(Lect, Phoneme, Tone, Onset, Nucleus, Coda)]

Eurasia$Lect
```

Make a list of lects and their geographical coordinates.

```{r Lects and coordinates}
Lect_LonLat <- Phonotacticon %>%
  .[Lect %in% Eurasia$Lect] %>%
  .[, .(Lect, lon, lat)]
  
Lect_LonLat
```

Load map data.

```{r Map}
map <- map_data("world")

head(map)
```

Create a map of Eurasia.

```{r Map of Eurasia}
EurasiaMap <- ggplot(map, aes(x = long, y = lat)) +
  geom_polygon(aes(group = group),
               fill = "white",
               color = "darkgrey",
               linewidth = 0.2) +
  coord_map("ortho",
            orientation = c(20, 70, 0),
            xlim = c(10, 130),
            ylim = c(0, 90)) +
  theme_void()

EurasiaMap
```

Modified version of PanPhon.

```{r PanPhon}
PanPhon <- fread("PanPhonPhonotacticon1_0.csv") %>%
  as.data.table() %>%
  unique(by = 'ipa')

PanPhon
```

Check if all phonemic transcriptions are present in PanPhon.

```{r Check transcriptions}
Transcriptions <- Eurasia$Phoneme %>% 
  str_split_fixed(pattern = ' ', n = Inf) %>% 
  as.data.table() %>% 
  melt(measure.vars = colnames(.)) %>% 
  select(-variable) %>% 
  filter(value != '') %>% 
  distinct() %>% 
  mutate(Correct = value %in% PanPhon$ipa)

all(Transcriptions$Correct)
```

# Sequences of each lect

In this section, I will analyze the sequences of each lect.

Arrange PanPhon segments in alphabetical order.

```{r PanPhon order}
PanPhonOrder <- PanPhon$ipa[
                  order(-nchar(PanPhon$ipa),
                      PanPhon$ipa)]

head(PanPhonOrder, 10)
```

Create a regex line of PanPhon in order to split the segments from sequences.

```{r PanPhon regex}
PanPhonRegex <- paste0("(?:",
                       paste(PanPhonOrder, collapse="|"),
                      '|B|C|Č|D|F|G|K|Ł|L|N|P|R|S|T|V|W|X|Z',
                       ")")

str_trunc(PanPhonRegex, 100)
```

Create PanPhon regex including brackets, in order to detect segments within brackets (e. g. [ptk] meaning "/p/, /t/, or /k/".).

```{r PanPhon regex including brackets}
PanPhonRegexBrackets <- paste0('(?:',
                               '(?<=\\[).*?(?=\\])|',
                               paste(PanPhonOrder, collapse="|"),
                               '|B|C|Č|D|F|G|K|Ł|L|N|P|R|S|T|V|W|X|Z',
                               ')')

str_trunc(PanPhonRegexBrackets, 100)
```

Define "classes", i. e. underspecified segments transcribed in capitals (e. g. P for plosives).

```{r Classes}
Classes <- PanPhon %>%
  mutate(B = cons == 1 & lab == 1,
        C = cons == 1,
        Č = cons == 1 & delrel == 1 & son == -1 & cont == -1,
        `F` = cons == 1 & cont == 1 & son == -1,
        G = grepl('j|w|ɥ|ɰ', ipa),
        Ł = cons == 1 & cor == 1 & lat == 1,
        L = cons == 1 & cont == 1 & cor == 1 & son == 1,
        N = nas == 1 & syl == -1,
        P = cons == 1 & cont == -1 & delrel == -1 & son == -1,
        R = cont == 1 & son == 1 & syl == -1 & !grepl('h|ɦ', ipa),
        S = cons == 1 & cont == 1 & cor == 1 & son == -1,
        `T` = cons == 1 & son != 1,
        V = cons == -1 & cont == 1 & son == 1 & syl == 1,
        W = syl == -1 & voi == 1,
        X = syl == -1 & voi == -1,
        Z = cont == 1 & syl == -1) %>%
  select(ipa, B, C, Č, `F`, G, Ł, L, N, P, R, S, `T`, V, W, X, Z) %>%
  pivot_longer(cols = -ipa,
     names_to = 'Class',
     values_to = 'Value') %>%
  filter(Value) %>%
  select(-Value)

Classes
```

Extract phonemes from the phonemic inventories.

```{r Phonemes}
Phonemes <- stri_extract_all_regex(Eurasia$Phoneme,
                         pattern = PanPhonRegex,
                         simplify = TRUE) %>%
  as.data.table() %>%
  mutate(Lect = Eurasia$Lect) %>%
  melt(id.vars = 'Lect',
       variable.name = 'Number',
       value.name = 'ipa') %>%
  select(-Number) %>%
  filter(ipa != '')

Phonemes
```

Subset lect, onsets, nuclei, and codas from Phonotacticon.

```{r Extract ONC}
LectONC <- Eurasia %>%
  .[, .(Lect, Onset, Nucleus, Coda)] %>%
  melt(id.vars = 'Lect',
       variable.name = 'Category',
       value.name = 'Sequence')

LectONC
```

Extract the sequences from onset, nucleus, and coda categories.

```{r Sequences}
Sequences <- LectONC[, tstrsplit(Sequence, ' ', fixed = FALSE)] %>%
  .[, c('Lect', 'Category') := .(LectONC$Lect, LectONC$Category)] %>% 
  melt(id.vars = c('Lect', 'Category'),
       variable.name = 'Number',
       value.name = 'Sequence') %>%
  .[, -c('Number')] %>%
  .[!is.na(Sequence)] %>%
  distinct()

Sequences
```

Subset sequences that include underspecified segments (transcribed in capital letters).

```{r Capitals}
Capitals <-
  Sequences %>%
  .[grepl('B|C|Č|F|G|Ł|L|N|O|P|R|S|T|V|W|X|Z', Sequence)] %>%
  .[, -c('Category')] %>%
  distinct()

Capitals
```

Convert the capital letters into the corresponding phonemes in each lect. For example, P ("plosive") in Italian is converted to all the plosive phonemes in Italian phonemic inventory.

```{r Decapitalized}
Decapitalized <-
  stri_extract_all_regex(Capitals$Sequence,
                         pattern = PanPhonRegex,
                         simplify = TRUE) %>%
  as.data.table() %>%
  .[, c('Lect', 'Sequence') := 
      .(Capitals$Lect, Sequence = Capitals$Sequence)] %>%
  melt(id.vars = c('Lect', 'Sequence'),
        variable.name = 'Order',
       value.name = 'Class') %>%
  .[, Order := as.integer(as.factor(Order))] %>% 
  .[Class != ''] %>%
  merge(Classes, all = TRUE, allow.cartesian = TRUE) %>%
  .[, ipa := if_else(is.na(ipa), Class, ipa)] %>%
  .[, -c('Class')] %>%
  merge(Phonemes) %>%
  setorder(col = Order) %>%
  split(by = c('Lect', 'Sequence')) %>%
  lapply(function(x)
           split(x, by = 'Order')) %>%
  lapply(function(x)
    lapply(x, function(x)
      x <- x$ipa)) %>%
  lapply(function(x)
    expand.grid(x) %>%
      do.call(what = paste0)) %>%
  enframe() %>%
  unnest() %>%
  as.data.table() %>%
  separate(col = name,
           into = c('Lect', 'Sequence'),
           sep = '\\.') %>%
  setnames('value', 'NewSequence') %>%
  merge(Sequences, all = TRUE) %>%
  mutate(Sequence =
           if_else(!is.na(NewSequence),
                   NewSequence,
                   Sequence)) %>%
  .[, -c('NewSequence')]

Decapitalized
```

Split the sequences into segments, including bracketed segments (such as [ptk] for "/p/, /t/, or /k/.).

```{r Split segments to unbracket}
ToUnbracket <- stri_extract_all_regex(Decapitalized$Sequence,
                         pattern = PanPhonRegexBrackets,
                         simplify = TRUE) %>%
  as.data.table() %>%
  mutate(Lect = Decapitalized$Lect,
         Category = Decapitalized$Category,
         Sequence = Decapitalized$Sequence) %>%
  melt(id = c('Lect', 'Category', 'Sequence'),
       variable.name = 'Order',
       value.name = 'ipa') %>%
  mutate(Order = Order %>%
           as.factor() %>%
           as.integer()) %>%
  filter(ipa != "")

ToUnbracket
```

Subset bracketed sequences.

```{r Bracketed}
Bracketed <- ToUnbracket %>%
  filter(grepl('\\[', Sequence))

Bracketed
```

Convert the bracketed sequences into all logically possible sequences. For example, Laven's sequence [bdɟɡ] [rl] is converted into /br/, /bl/, /dr/, /dl/, /ɟr/ /ɟl/, /ɡr/, and /ɡl/.

```{r Unbracketed}
Unbracketed <- Bracketed$ipa %>%
  stri_extract_all_regex(pattern = PanPhonRegex, simplify = TRUE) %>%
  as.data.table() %>%
  mutate(Sequence = Bracketed$Sequence,
         Order = Bracketed$Order) %>%
  melt(id.vars = c('Sequence', 'Order'),
       variable.name = 'Number',
       value.name = 'ipa') %>%
  filter(ipa != '') %>%
  select(-Number) %>%
  setorder(col = Order) %>%
  split(by = 'Sequence') %>%
  lapply(function(x)
    split(x, by = 'Order')) %>%
  lapply(function(x)
    lapply(x, function(x)
      x <- x$ipa)) %>%
  lapply(function(x)
    expand.grid(x) %>%
      do.call(what = paste0)) %>%
  enframe() %>%
  unnest() %>%
  setnames(c('name', 'value'),
           c('Sequence', 'NewSequence')) %>% 
  as.data.table()

Unbracketed
```

Join the unbracketed sequences into the whole list of sequences. Then split the sequences into segments (e. g. /pl/ into /p/ and /l/).

```{r Segments}
Segments <-
  stri_extract_all_regex(
  Unbracketed$NewSequence,
  pattern = PanPhonRegex,
  simplify = TRUE) %>%
  as.data.table() %>%
  mutate(Sequence = Unbracketed$Sequence,
         NewSequence = Unbracketed$NewSequence) %>%
    pivot_longer(cols = -c(Sequence, NewSequence),
               names_to = 'Order',
               values_to = 'NewIPA') %>%
    mutate(Order = Order %>%
           as.factor() %>%
           as.integer()) %>%
  filter(NewIPA != '') %>%
  full_join(ToUnbracket) %>%
  mutate(Sequence =
           if_else(
             !is.na(NewSequence),
             NewSequence,
             Sequence),
         ipa =
           if_else(
             !is.na(NewIPA),
             NewIPA,
             ipa)) %>%
  select(-NewSequence, -NewIPA) %>% 
  as.data.table()

Segments
```

# Length of sequences

In this section, I will measure the length of each sequence, where length is the number of segments that consist a sequence.

Measure the length of each sequence, in terms of the number of segments involved.

```{r Measure length}
Sequences_length <- Segments %>% 
  .[, .(Length = max(Order)), by = .(Lect, Category, Sequence)]

Sequences_length
```

Join the length of each sequence to segments.

```{r Join length}
Segments <- left_join(Segments, Sequences_length)

Segments
```

# Distance between sequences

In this section, I will show how I measure the distance between two sequences, e. g. between /pl/ and /spl/.

Count the maximal length of all sequences.

```{r Maximal length}
MaxLength <- max(Sequences_length$Length)

MaxLength
```

Count the number of all the split segments.

```{r Count split segments}
Segments_number <- nrow(Segments)

Segments_number
```

In order to measure the distance between two sequences of different length. I assign different "positions" to each sequence. As the maximal length of all sequences is six, a sequence of only one segment has six positions within these six slots (from 0 to 5).

```{r Assign positions}
Sequences_rep <- bind_rows(rep(list(Segments), MaxLength))  %>%
  mutate(Position = rep(0:(MaxLength - 1),
                        each = Segments_number)) %>%
  mutate(Order = Order + Position) %>%
  filter(Length + Position <= MaxLength) %>%
  select(-Length)

Sequences_rep
```

Join segments with their phonological features (retrieved from PanPhon). Each feature is assigned the value of the position.

```{r Join segments and features}
Sequences_features <- Sequences_rep %>%
  left_join(PanPhon, by = 'ipa') %>%
               melt(id = c('Lect',
                         'Category',
                         'Sequence',
                         'Order',
                         'ipa',
                         'Position'),
               variable.name = 'Feature',
               value.name = 'Value') %>%
  mutate(Feature = paste0(Feature, Order)) %>%
  dcast(Lect + Category + Sequence + Position ~ Feature,
        value.var = 'Value',
        fun.aggregate = sum,
        fill = 0) %>%
  mutate(SequencePosition = paste0(Sequence, Position)) %>%
  select(-Lect, -Category, -Position, -Sequence) %>%
  distinct() %>% 
  as.data.table()

Sequences_features
```

Calculate the Saporta distance between each pair of sequences.

```{r Calculate sequence distance}
Sequences_distance <- Sequences_features %>%
  .[, !'SequencePosition', with = FALSE] %>% 
  Dist(method = 'manhattan') %>% 
  as.data.table()

Sequences_distance[1:10, 1:10]
```

In order to name the rows and the columns of the distance matrix, create a vector of all sequences in different positions.

```{r Sequence vectors}
SequenceVectors <-
  str_replace(Sequences_features$SequencePosition, '[0-9]', '')

head(SequenceVectors, 10)
```

Use this vector to name the rows and the columns of the distance matrix.

```{r Name the rows and columns of the distance matrix}
Sequences_distance[, Sequence := SequenceVectors]

setcolorder(Sequences_distance, 
            c(ncol(Sequences_distance), 1:(ncol(Sequences_distance) - 1)))

setnames(Sequences_distance, c('Sequence', Sequences_features$SequencePosition))

Sequences_distance[1:10, 1:10]
```

As I have shown above, I need to choose the minimal distance between two sequences mapped onto each other in different positions. Thus I calculate the minimal distance per each sequence pair.

Make a vector of all sequences.

```{r Vector of all sequences}
AllSequences <- unique(Segments$Sequence)

head(AllSequences)
```

Calculate the minimal distance of every sequence to each sequence.

```{r Minimal distance between sequences}
for (i in AllSequences){
  
  csv_name <- paste0('~/Phonotacticon/Sequences/', i, '.csv')
  
  OneSequence <-
    Sequences_distance[Sequence == i] %>% 
    melt(id.vars = 'Sequence',
         variable.name = 'i.Sequence',
         value.name = 'Distance') %>% 
    .[, i.Sequence := gsub('[0-9]', '', i.Sequence)] %>% 
    .[, .(Distance = min(Distance)),
     by = .(i.Sequence)] %>% 
    .[, Sequence := i]
  
  fwrite(OneSequence, csv_name)
}
```

Make a list of the sequence file names.
```{r List of sequence file names}
Sequences_file_list <- 
  list.files(path = '~/Phonotacticon/Sequences', 
             pattern = '.*')

head(Sequences_file_list)
```

Read them into a data table.
```{r Read sequence files}
Sequences_MinDistance <- 
  map_df(Sequences_file_list, ~ fread(paste0('~/Phonotacticon/Sequences/', .x))) %>% 
  as.data.table()

Sequences_MinDistance
```

# Distance between lects

In this section, I will show how I measure the phonological distance between two lects.

Redefine sequences with new (decapitalized and unbracketed) sequences.

```{r New sequences}
NewSequences <- Segments %>%
  select(Lect, Category, Sequence)

NewSequences
```

Split the data.table of sequences into separate lects.

```{r Split data.table of sequences into separate lects}
for (i in Eurasia$Lect){
  csv_name <- paste0('~/Phonotacticon/Lects/', i, '.csv')
  
  Lect <- NewSequences[Lect == i]
  
  fwrite(Lect, csv_name)
}
```

Assign every onset/nucleus/coda sequence to every other onset/nucleus/coda sequence.

```{r Assign every sequence to every other sequence}
for (i in Eurasia$Lect){
  csv_name <- paste0('~/Phonotacticon/Lects/', i, '.csv')
  
  Lect <- fread(csv_name) %>% 
    as.data.table() %>% 
    .[Sequences_MinDistance, on = .(Sequence), nomatch = 0]
  
  fwrite(Lect, csv_name)
}
```

Calculate the minimal distance between the onset/nucleus/coda inventory of each pair of lects.

```{r Minimal distance between onset/nucleus/coda inventory}
for (i in Eurasia$Lect){

  csv_name <- paste0('~/Phonotacticon/Lects/', i, '.csv')

  Lect <- 
    fread(csv_name) %>% 
    as.data.table() %>% 
    .[NewSequences,
      on = .(Category, 
             i.Sequence = Sequence),
      allow.cartesian = TRUE] %>% 
    .[, .(Distance = min(Distance)),
      by = .(i.Lect, Sequence, Category)] %>% 
    .[, .(Distance = mean(Distance)),
         by = .(i.Lect, Category)]
  
  Lect$Lect <- i

  fwrite(Lect, csv_name)
  
}
```

Make a list of .csv file names.
```{r List of lect .csv file names}
Lects_file_list <- 
  list.files(path = '~/Phonotacticon/Lects', 
             pattern = '.*')

head(Lects_file_list)
```

Read the .csv files into a data.table.
```{r Read the lect .csv files}
ONC_distance_mean <- 
  map_df(Lects_file_list, ~ fread(paste0('~/Phonotacticon/Lects/', .x))) %>% 
  as.data.table()

ONC_distance_mean
```

In order to create a data.table of lect pairs, make a dummy column.
```{r Dummy column}
LectDummy <- Lect_LonLat %>% 
  mutate(Dummy = 'Dummy')

LectDummy
```

Create a data.table of lect pairs.
```{r Data.table of lect pairs}
Lect_vs_Lect <- LectDummy %>% 
  .[LectDummy, on = 'Dummy', allow.cartesian = TRUE] %>% 
  .[, Lect_vs_Lect := str_c(pmin(as.character(Lect), as.character(i.Lect)),
                                'vs.',
                                pmax(as.character(Lect), as.character(i.Lect)),
                               sep = ' ')] %>% 
  .[, -c('Dummy')]

Lect_vs_Lect
```

Assign the lect pair column to the mean distances and then detect the maximal distance between the Lect A vs. Lect B pair and the Lect B vs. Lect A pair. The result is the onset/nucleus/coda distance between each pair of lects.

```{r Onset/nucleus/coda distances}
ONC_distance <-
  ONC_distance_mean %>% 
  .[Lect_vs_Lect, on = .(Lect, i.Lect)] %>% 
  .[, .(Lect_vs_Lect, Category, Distance)] %>% 
  .[, .(Distance = max(Distance)),
      by = .(Lect_vs_Lect, Category)] %>% 
    dcast(., Lect_vs_Lect ~ Category, value.var = 'Distance') %>% 
  relocate(Lect_vs_Lect, Onset, Nucleus, Coda)

ONC_distance
```

# Distance of tones

Next, I calculate the distance between the tonality of each pair of lects.

Count the number of tones in each lect.

```{r Tones}
Tones <- Eurasia %>%
  .[, .(Lect, Tone)] %>%
  .[, Tone := gsub("\\-", NA, Tone)] %>%
  .[, Tone := str_count(Tone, " ") + 1]

Tones[is.na(Tones$Tone),]$Tone <- 0

Tones
```

Calculate the Canberra distance between the numbers of tones of each pair of lects.

```{r Canberra distance}
Tones_distance <- Tones %>% 
  .[, -c('Lect')] %>% 
  dist(method = 'canberra') %>%
  as.matrix() %>%
  as.data.table() %>%
  setnames(Tones$Lect) %>%
  .[, Lect := Tones$Lect] %>%
  melt(id = 'Lect',
       variable.name = 'Lect2',
       value.name = 'Tone') %>%
  .[, Tone := replace_na(Tone, 0)] %>%
  .[, Lect_vs_Lect := str_c(pmin(as.character(Lect), as.character(Lect2)),
                                'vs.',
                                pmax(as.character(Lect), as.character(Lect2)),
                               sep = ' ')] %>%
  .[, .(Lect_vs_Lect, Tone)] %>%
  distinct()

Tones_distance
```

Join segmental distance with tonal distance and normalize the four distances.

```{r ONCT distance}
ONCT_distance <- ONC_distance %>%
  full_join(Tones_distance) %>% 
  select(-Lect_vs_Lect) %>% 
  scale() %>% 
  as.data.table() %>% 
  mutate(Lect_vs_Lect = ONC_distance$Lect_vs_Lect) %>% 
  relocate(Lect_vs_Lect)

ONCT_distance
```

# Overall distance

Calculate the overall distance, which is the Euclidean distance between each pair of lects based on their four normalized distances (onset, nucleus, coda, and tone).

```{r Overall distance}
PhonoDist <- ONCT_distance %>%
  mutate(Distance = sqrt((Onset - min(Onset)) ^ 2 +
                         (Nucleus - min(Nucleus)) ^ 2 +
                         (Coda - min(Coda)) ^ 2 +
                         (Tone - min(Tone)) ^ 2)) %>%
  select(Lect_vs_Lect, Distance)

PhonoDist
```

# Clustering the lects

Based on these distances, I cluster similar lects together and detect areal patterns.

Create a data.table consisting only of phonological distances.

```{r PhonoDistNumbers}
PhonoDistNumbers <- PhonoDist %>%
  .[Lect_vs_Lect, on = .(Lect_vs_Lect)] %>% 
  .[, .(Lect, i.Lect, Distance)] %>%
  dcast(Lect ~ i.Lect, value.var = 'Distance') %>% 
  .[, !'Lect']

PhonoDistNumbers
```

Create a data.table for clusters.

```{r Data table for clusters}
PhonoClusters <-
  Lect_LonLat

PhonoClusters
```

Cluster the lects into two, three, and four groups.

```{r K2, K3, K4} 
PhonoClusters$K2 <- 
  PhonoDistNumbers %>%
    kmeans(2) %>%
    pluck(1) %>%
    as_factor()

PhonoClusters$K3 <- 
  PhonoDistNumbers %>%
    kmeans(3) %>%
    pluck(1) %>%
    as_factor()

PhonoClusters$K4 <- 
  PhonoDistNumbers %>%
    kmeans(4) %>%
    pluck(1) %>%
    as.numeric() %>%
    as.factor()
  
PhonoClusters
```

Assign the two clusters on the map of Eurasia, each integer in different colors representing different clusters.

```{r K2 map}
PhonoK2 <- EurasiaMap +
  geom_text(aes(x = lon,
                 y = lat,
                 label = K2,
                 color = K2),
             data = PhonoClusters,
            show.legend = FALSE) 

PhonoK2
```

Three clusters on the map.

```{r K3 map}
PhonoK3 <- EurasiaMap +
  geom_text(aes(x = lon,
                 y = lat,
                 label = K3,
                color = K3),
             data = PhonoClusters,
            show.legend = FALSE)

PhonoK3
```

Four clusters on the map.

```{r K4 map}
PhonoK4 <- EurasiaMap +
  geom_text(aes(x = lon,
                 y = lat,
                 label = K4,
                 color = K4),
             data = PhonoClusters,
            show.legend = FALSE)

PhonoK4
```

# Multidimensional scaling

Perform multidimensional scaling (k = 2) based on the phonological distances, while grouping the lects into Eastern, Central, and Western Eurasia.

```{r}
PhonoMDS <- cmdscale(PhonoDistNumbers) %>% 
  as.data.table() %>% 
  mutate(Lect = Eurasia$Lect) %>% 
  left_join(Phonotacticon) %>% 
  mutate(Area = ifelse(lon < 60 & lon > -20,
                       'West',
                       ifelse(lon > 90 | lon < -160,
                       'East', 'Central'   
                       ))) %>% 
  select(Lect, Family, V1, V2, Area) %>% 
  mutate(Area = factor(Area, levels = c('West', 'Central', 'East')))

PhonoMDS
```

Visualization of multidimensional scaling.
```{r}
PhonoMDSggplot <- 
  ggplot(aes(x = V2, y = V1, shape = Area, color = Area, label = Lect),
         data = PhonoMDS) +
  geom_point() +
  geom_text_repel(min.segment.length = 0,
                  max.overlaps = 10,
                  force = 5,
                  size = 3,
                  show.legend = FALSE) +
  scale_shape_manual(values = 0:2,
                     labels = c('Western (west of the Ural Mountains, defined as 60°E)',
                                'Central (60-90°E)',
                                'Eastern (east of the Eastern Himalayas, defined as 90°E)')) +
  theme_classic() +
  guides(color = guide_legend(nrow = 3)) +
  theme(legend.position = 'bottom') +
  coord_fixed() +
  guides(color = guide_legend(direction = "vertical"),
         shape = guide_legend(direction = "vertical")) +
  scale_color_manual(values = c('red', 'purple', 'blue'),
                     labels = c('Western (west of the Ural Mountains, defined as 60°E)',
                                'Central (60-90°E)',
                                'Eastern (east of the Eastern Himalayas, defined as 90°E)'))

PhonoMDSggplot
```


# DIANA

Draw a dendrogram based on the phonological distances.

```{r}
PhonoDendro <- PhonoDistNumbers %>% 
  as.dist() %>% 
  diana() %>% 
  as.dendrogram() %>% 
  ggdendrogram(rotate = T) +
  theme(axis.text.x = element_blank())

PhonoDendro
```

# Correlation between phonological and geographical distances

I will also test the following hypothesis: Geographical distance correlates with phonological distance. That is, geographically closer lects also tend to be phonologically similar.

Subset Coordinates x.

```{r Coordinates x}
Coordinates.x <- select(Lect_vs_Lect, lon, lat)

head(Coordinates.x)
```

Subset Coordinates y.

```{r Coordinates y}
Coordinates.y <- select(Lect_vs_Lect, i.lon, i.lat)

head(Coordinates.y)
```

Calculate the geographical distances between two columns of coordinates. Leave out pairs of lects that belong to the same family, as lects belonging to the same family tend to be phonologically similar (by inheritance) and also geographically closer.

```{r Geographical distances}
GeoDist <- Lect_vs_Lect %>%
  mutate(Kilometers =
           distHaversine(Coordinates.x, Coordinates.y) / 1000) %>%
  select(Lect_vs_Lect, Kilometers) %>%
  distinct()

GeoDist
```

Join the phonological distances to the geographical distances.

```{r Join phonological and geographical distances}
PhonoGeoDist <- GeoDist %>% 
  .[PhonoDist, on = .(Lect_vs_Lect), nomatch = 0] %>% 
  .[Lect_vs_Lect, on = .(Lect_vs_Lect), nomatch = 0] %>% 
  filter(Lect != i.Lect)

PhonoGeoDist
```

Set Burushaski, a language isolate spoken in the middle of Eurasia, as a reference point. The hypothesis is that, the closer a Eurasian Lect is to Burushaski geographically, the closer it is to Burushaski phonologically.

```{r Burushaski}
Burushaski <- PhonoGeoDist %>% 
  filter(i.Lect == 'Burushaski') %>% 
  select(-i.Lect, -i.lon, -i.lat)

Burushaski
```

Subset the coordinates of the Burushaski data.table.

```{r Linear regression}
BurushaskiCoords <-
  Burushaski %>% 
  select(lon, lat)

BurushaskiCoords
```

Among all the lects other than Burushaski, calculate the greatest distance from a lect to its nearest neighbor.

```{r Maximal distance}
MaxDistance <- 
  BurushaskiCoords %>% 
  knearneigh(k = 1, longlat = TRUE) %>% 
  knn2nb() %>% 
  nbdists(BurushaskiCoords, longlat = TRUE) %>% 
  unlist() %>% 
  max()
  
MaxDistance
```

Assign the neighbors to each lect, a neighbor defined as a lect within the maximal distance calculated above, so that every lect has at least one neighbor.
```{r Weight matrix}
WeightMatrix <- 
  BurushaskiCoords %>% 
  dnearneigh(0, MaxDistance, longlat = TRUE) %>% 
  nb2listw(style = 'W')

WeightMatrix
```

Perform the Moran's I test to test the spatial autocorrelation, which shows that the phonological distance patterns are areally clustered.

```{r Morans test}
moran.test(Burushaski$Distance, WeightMatrix)
```

Perform a spatial regression analysis based on the spatial lag model.
```{r Spatial regression}
SpatialLag <- 
  lagsarlm(Distance ~ Kilometers,
         Burushaski,
         listw = WeightMatrix)

summary(SpatialLag)
```

Visualize the phonological distances to Burushaski on a map of Eurasia.
```{r Burushaski map}
BurushaskiMap <- EurasiaMap +
  geom_text(aes(x = lon,
                 y = lat,
                 color = Distance,
                 label = as.integer(round(Distance))),
             data = Burushaski,
            show.legend = FALSE) +
  geom_point(x = 74.8, y = 36.2, color = 'black', fill = 'red', shape = 21, size = 3) +
  scale_color_gradient(low = 'red', high = 'black')

BurushaskiMap
```


# Naive Bayes Classifier

As a follow-up study, I will examine how well machine learning predicts the the area of a lect given its phonological distance from other lects. For example, based on how similar German is to other Eurasian lects, can we predict that it is spoken in Europe?

Divide the Eurasian lects into seven different regions solely based on their geographical coordinates: Northeast Asia, Mainland Southeast Asia, Qinghai-Gansu, South Asia, West Asia, Caucasus, and Europe.

```{r Regions}
Areas <- Lect_LonLat %>% 
  mutate(Area = 
           ifelse(lon > 90 & lon < 105 & lat > 32 & lat < 40,
                 'Qinghai-Gansu',
           ifelse(lon > 90 & lat <= 32,
                  'Mainland Southeast Asia',
           ifelse(lon > 60 & lon <= 90 & lat < 40,
                  'South Asia',
           ifelse(lon > 25 & lon < 50 & lat < 50,
                  'West Asia',
           ifelse(lon > -25 & lon < 50 & lat > 30,
                  'Europe',
                  'Northeast Asia')))))) %>% 
  select(-lon, -lat)
                         
Areas
```

The map visualizes the lects in the predefined seven areas.

```{r Areas visualized}
AreasLonLat <- Areas %>% 
  left_join(Lect_LonLat)

AreaMap <- EurasiaMap +
  geom_point(aes(x = lon,
                 y = lat,
                 color = Area,
                 shape = Area),
             data = AreasLonLat) +
  scale_shape_manual(values = 0:5) +
  theme(legend.position = 'bottom')

AreaMap
```

The goal is to train a model based on phonological distance to see how well it predicts which one of these six areas a lect is spoken.

Split the Lect vs. Lect column of the PhonoDist table into two lects.

```{r Split Lect vs Lect}
Lect_iLect <- str_split_fixed(
  PhonoDist$Lect_vs_Lect, ' vs. ', n = 2) %>%
  as.data.table() %>%
  setnames(c('Lect', 'i.Lect'))

Lect_iLect
```

Join the distances to the split lect pairs.
```{r Split PhonoDist}
PhonoDistSplit <- PhonoDist %>% 
  bind_cols(Lect_iLect) %>% 
  select(-Lect_vs_Lect)

PhonoDistSplit
```

Double the split distances by switching Lect.x and Lect.y.

```{r Double the distance table}
PhonoDistDouble <- PhonoDistSplit %>% 
  rename(c('Lect' = 'i.Lect',
           'i.Lect' = 'Lect')) %>% 
  bind_rows(PhonoDistSplit)

PhonoDistDouble
```

Make a matrix consisting of lects, their distances from all other lects, and their area.

```{r Widen the PhonoDist}
PhonoDistWide <- PhonoDistDouble %>% 
  pivot_wider(names_from = i.Lect,
              values_from = Distance,
              values_fn = sum) %>% 
  left_join(Areas) %>% 
  as.data.table()

setcolorder(PhonoDistWide, 
            c(ncol(PhonoDistWide), 
            1:(ncol(PhonoDistWide) - 1)))

PhonoDistWide
```

Train the Naive Bayes Classifier based on half of the lects and their distance from other lects. First, divide the sample in half by each area. (The proportion of the areas is thus equal in the halved sample.) Then train the classifier in the first half and test it on the other half.

```{r Calculate the number of sample lects divided in half}
AreaSample <- Areas %>% 
  group_by(Area) %>% 
  slice_sample(prop = 0.5)

AreaSample
```

Subset the first half of the lects and their distances, which I will train the Naive Bayes Classifier with.

```{r Half to train}
Train <- PhonoDistWide[Lect %in% AreaSample$Lect]

Train
```

The remaining half will be the lects where the Naive Bayes Classifier will be tested upon to predict their areas.

```{r Half to test}
Test <- PhonoDistWide %>% 
  filter(!(Lect %in% Train$Lect)) %>% 
  select(-Area)

Test
```

Train the classifier.

```{r Training}
Classifier <- naiveBayes(Area ~ ., Train)

Classifier[1]
```

The trained classifier then predicts the areas of the remaining lects.

```{r Testing}
Predict <- predict(Classifier, newdata = Test)

Predict
```

Join the predicted areas into the table of tested lects.

```{r Area prediction 1}
AreaPrediction1 <- Test %>% 
  select(Lect) %>% 
  mutate(Prediction = Predict) %>% 
  left_join(Areas) %>% 
  mutate(Correct = Prediction == Area)

AreaPrediction1
```

Perform the same training and testing, but training with the latter half as the training and testing the former half.

```{r Area prediction 2}
Train2 <- Test %>% 
  left_join(Areas)

Test2 <- Train %>% 
  select(-Area)

Classifier <- naiveBayes(Area ~ ., Train2)

Predict2 <- predict(Classifier, newdata = Test2)

AreaPrediction2 <- Test2 %>% 
  select(Lect) %>% 
  mutate(Prediction = Predict2) %>% 
  left_join(Areas) %>% 
  mutate(Correct = Prediction == Area)

AreaPrediction2
```

Join the two halves whose areas are predicted based on each other.

```{r Area prediction 1 + 2}
AreaPrediction <- bind_rows(AreaPrediction1, AreaPrediction2)

AreaPrediction
```

I will analyze how correctly the model has predicted the areas based on confusion matrix. 

Make the predefined areas into factors.

```{r Area factors}
AreaFactors <- as.factor(AreaPrediction$Area)

head(AreaFactors)
```

Make the predicted areas into factors.

```{r Prediction factors}
PredictionFactors <- factor(AreaPrediction$Prediction,
                            levels = levels(AreaFactors))

head(PredictionFactors)
```

Below is the confusion matrix and the related statistics, based on the combination of the two halves of prediction: 

```{r Kappa}
ConfusionMatrix <- 
  confusionMatrix(PredictionFactors,
                AreaFactors,
                mode = 'everything')

ConfusionMatrixOverall <-
  ConfusionMatrix$overall %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  rownames_to_column()

colnames(ConfusionMatrixOverall) <- c('Name', 'Value')

ConfusionMatrixOverall
```

The F1 values of individual classes.

```{r F1}
F1 <- ConfusionMatrix$byClass %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  rename(c('Class' = 'rowname')) %>% 
  mutate(Class = gsub('Class: ', '', Class)) %>% 
  select(Class, F1)

F1
```

The visualization of the lects by their predicted areas.

```{r Arrange the predictions by family name}
AreaPredictionLonLat <- AreaPrediction %>% 
  left_join(Lect_LonLat)

AreaPredictionMap <- EurasiaMap +
  geom_point(aes(x = lon, 
                 y = lat,
                 color = Prediction,
                 shape = Prediction),
             data = AreaPredictionLonLat) +
  scale_shape_manual(values = 0:6) +
  theme(legend.position = 'bottom')

AreaPredictionMap
```

# Grambank

Load Eurasian lects of Grambank.
```{r Load Grambank lects}
GrambankLects <- fread('GrambankLects.csv') %>% 
  as.data.table() %>% 
  .[Macroarea == 'Eurasia'] %>% 
  .[, .(ID, Longitude, Latitude)]

GrambankLects
```

Load Grambank and subset to lects present in PanPhon.

```{r Load Grambank}
Grambank <- fread('Grambank.csv') %>% 
  as.data.table() %>% 
  .[Language_ID %in% GrambankLects$ID] %>% 
  .[, .(Language_ID, Parameter_ID, Value)]

Grambank
```

Detect non-binary features.
```{r Non-binary features}
NonBinary <- Grambank %>% 
  .[Value == 2] %>% 
  .[, .(Parameter_ID)] %>% 
  distinct() %>% 
  unlist() %>% 
  as.vector()

NonBinary
```

Exclude non-binary features and numeralize the values.
```{r Exclude non-binary features}
GrambankBinary <- Grambank %>% 
  .[!(Parameter_ID %in% NonBinary)] %>% 
  .[, Value := gsub(0, -1, Value)] %>% 
  .[, Value := gsub('\\?', 0, Value)] %>% 
  .[, Value := as.numeric(Value)]

GrambankBinary
```

Calculate the proportion of unknown values.
```{r Unknown values}
Unknown <-  GrambankBinary %>%
  .[Value == 0] %>% 
  .[, .N]/nrow(GrambankBinary)

Unknown
```

Create a vector of glottocodes.
```{r Vector of Glottocodes}
Glottocodes <- GrambankBinary$Language_ID %>% 
  unique()

Glottocodes[1:10]
```


Widen the Grambank data table.
```{r GramDist}
GramDist <- GrambankBinary %>% 
  dcast(Language_ID ~ Parameter_ID, value.var = 'Value', fill = 0) %>% 
  .[, Language_ID := NULL] %>% 
  dist(method = 'manhattan')

GramDist[1:10]
```
Load Glottocode-lect name data

```{r}
GlottocodeLect <- read.csv('glottolog-cldf-4.4/cldf/languages.csv') %>% 
  as.data.table() %>% 
  .[, c('ID', 'Name')] %>% 
  setNames(c('Glottocode', 'Lect'))

GlottocodeLect
```


K-means clustering (2).
```{r GramK2}
GramK2 <- GramDist %>% 
  kmeans(2) %>%
  pluck(1) %>%
  as_factor()

GramK2[1:10]
```

K-means clustering (3).
```{r GramK3}
GramK3 <- GramDist %>% 
  kmeans(3) %>%
  pluck(1) %>%
  as_factor()

GramK3[1:10]
```

K-means clustering (4).
```{r GramK4}
GramK4 <- GramDist %>% 
  kmeans(4) %>%
  pluck(1) %>%
  as_factor()

GramK4[1:10]
```


Make a data.table of Glottocodes, coordinates, and K.
```{r GramK}
GramK <-
  data.table(Glottocode = Glottocodes,
             K2 = GramK2,
             K3 = GramK3,
             K4 = GramK4) %>% 
  .[GrambankLects, on = .(Glottocode = ID), nomatch = 0]

GramK
```

K2 map.
```{r GramK2 map}
GramK2 <- EurasiaMap +
  geom_text(aes(x = Longitude,
                 y = Latitude,
                 label = K2,
                 color = K2),
             data = GramK,
            show.legend = FALSE)

GramK2
```

K3 map.
```{r GramK3 map}
GramK3 <- EurasiaMap +
  geom_text(aes(x = Longitude,
                 y = Latitude,
                 label = K3,
                 color = K3),
             data = GramK,
            show.legend = FALSE)

GramK3
```

K4 map.
```{r GramK4 map}
GramK4 <- EurasiaMap +
  geom_text(aes(x = Longitude,
                 y = Latitude,
                 label = K4,
                 color = K4),
             data = GramK,
            show.legend = FALSE)

GramK4
```

The Glottocodes of the intersecting lects.
```{r Intersecting lects}
Intersect <- Phonotacticon %>% 
  .[Lect %in% Eurasia$Lect] %>% 
  .[Glottocode %in% GrambankBinary$Language_ID] %>% 
  .[, .(Glottocode, Lect)]

Intersect
```

Subset PhonoDist into intersecting lects and widen it.
```{r Subset PhonoDist}
PhonoDistIntersect <- PhonoDist %>% 
  .[Lect_vs_Lect, on = .(Lect_vs_Lect)] %>% 
  .[Lect %in% Intersect$Lect & i.Lect %in% Intersect$Lect] %>% 
  .[, .(Lect, i.Lect, Distance)] %>% 
  dcast(Lect ~ i.Lect, value.var = 'Distance') %>% 
  .[, !c('Lect')] %>% 
  as.matrix() %>% 
  unname() %>%
  as.dist()

PhonoDistIntersect[1:10]
```

Subset GramDist into intersecting lects and widen it.
```{r Subset GramDist}
GramDistIntersect <- GrambankBinary %>% 
  .[Intersect, on = c(Language_ID = 'Glottocode'), nomatch = NULL] %>% 
  .[, Language_ID := NULL] %>% 
  dcast(Lect ~ Parameter_ID, value.var = 'Value', fill = 0) %>% 
  .[, Lect := NULL] %>% 
  dist(method = 'manhattan')

GramDistIntersect[1:10]
```

Mantel test
```{r Mantel test}
mantel(PhonoDistIntersect, GramDistIntersect, method = 'pearson')
```

# Comparing phonological distances to the number of shared genealogical layers

Load Glottolog data.
```{r Glottolog}
Glottolog <- fread('glottolog-cldf-4.4/cldf/values.csv') %>% 
  as.data.table()

Glottolog
```

Subset dialects.
```{r Dialects}
Dialects <- Glottolog %>% 
  .[Parameter_ID == 'category'] %>% 
  .[Value == 'Dialect'] %>% 
  .[, Language_ID]

head(Dialects)
```

Subset languages and their classification.
```{r Classification}
Classification <- Glottolog %>% 
  .[!Language_ID %in% Dialects] %>% 
  .[Parameter_ID == 'classification'] %>% 
  .[, .(Language_ID, Value)]

Classification
```

Split the classification column.
```{r Split classification}
Classification_split <- 
  str_split_fixed(Classification$Value, pattern = '/', n = Inf) %>% 
  as.data.table()

colnames(Classification_split) <- 
  c('Family', 1:(ncol(Classification_split) - 1)) %>% as.character()

Classification_split
```

Subset languages from Glottolog.
```{r GlottoLects}
GlottoLects <- Glottolog %>% 
  .[Value == 'language'] %>% 
  .[, Language_ID]

head(GlottoLects)
```

Melt the classification table and exclude bookkept and unclassified families.
```{r GeneaLects}
GeneaLects <- 
  Classification_split %>% 
  .[, Lect := Classification$Language_ID] %>% 
  .[Lect %in% GlottoLects] %>% 
  melt(id.vars = c('Lect', 'Family'),
       variable.name = 'Order',
       value.name = 'Branch') %>% 
  .[!(Order != 1 & Branch == '')] %>% 
  .[!Family %in% c('book1242', 'uncl1493')] %>% 
  .[Family != '<NA>'] %>% 
  .[Branch == '', Branch := Lect]

GeneaLects
```

Calculate the number of shared layers.
```{r SharedLayers}
SharedLayers <- GeneaLects %>% 
  .[GeneaLects, on = .(Family, Order), allow.cartesian = TRUE] %>% 
  .[Lect != i.Lect] %>% 
  .[, Shared := Branch == i.Branch] %>% 
  .[, .(Lect, i.Lect, Shared)] %>% 
  .[, .(SharedLayers = sum(Shared)), by = .(Lect, i.Lect)]

SharedLayers
```

Make a list of Glottocodes of Phonotacticon.
```{r PhonoGlottocodes}
PhonoGlottocodes <- Phonotacticon %>% 
  .[, .(Lect, Glottocode, Family)]

PhonoGlottocodes
```

Make a table of phonological distances and the number of shared layers.
```{r PhonoGenea}
PhonoGenea <- 
  Lect_iLect %>% 
  .[PhonoGlottocodes, on = .(Lect), nomatch = 0] %>% 
  .[PhonoGlottocodes, on = .(i.Lect = Lect), nomatch = 0] %>% 
  .[, Distance := PhonoDist$Distance] %>% 
  .[Family == i.Family & Lect != i.Lect] %>% 
  .[SharedLayers, on = .(Glottocode = Lect, i.Glottocode = i.Lect), nomatch = 0] %>% 
  .[, .(Lect, i.Lect, Family, Distance, SharedLayers)]

PhonoGenea
```

Subset families that have at least one layer and at least three sample lect pairs.
```{r PhonoGeneaFamily}
PhonoGeneaFamily <-
  PhonoGenea %>% 
  .[, Max := max(SharedLayers), by = .(Family)] %>% 
  .[Max >= 1] %>% 
  .[, .N, by = .(Family)] %>% 
  .[N >= 3] %>% 
  .[, .(Family)] %>% 
  pull(Family)

PhonoGeneaFamily
```

Test the correlation between the phonological distance and the number of shared layers.
```{r PhonoGeneaPearson}
PhonoGeneaPearson <- PhonoGenea %>% 
  .[Family %in% PhonoGeneaFamily] %>% 
  .[, cor.test(Distance, SharedLayers), by = Family] %>% 
  .[, .(Family, parameter, estimate, p.value)] %>% 
  .[!duplicated(.)] %>% 
  .[, parameter := as.integer(parameter + 2)] %>% 
  .[, p.value := p.adjust(p.value)] %>% 
  .[order(estimate)]

colnames(PhonoGeneaPearson) <- 
 c('Family', 'Number of lect pairs', 'r', 'FDR')

PhonoGeneaPearson
```

Convert the matrix of morphosyntactic distance into a data.table.
```{r GramDistDT}
GramDistDT <- GramDist %>% 
  as.matrix() %>% 
  as.data.table()

colnames(GramDistDT) <- GrambankLects$ID

GramDistDT
```

Retrieve the corresponding names of Glottocodes.
```{r GlottologNames} 
GlottologNames <- fread('glottolog-cldf-4.4/cldf/languages.csv') %>% 
  as.data.table() %>% 
  .[, .(ID, Name)]

GlottologNames
```

Make a table of the Eurasian lects of Grambank and their family.
```{r GramFamily}
GramFamily <- Glottolog %>% 
  .[Language_ID %in% Grambank$Language_ID &
      Parameter_ID == 'classification'] %>% 
  .[, .(Language_ID, Value)] %>% 
  .[Value == '<NA>', Value := Language_ID] %>% 
  .[, Value := sapply(strsplit(Value, "/"), function(x) x[1])] %>% 
  .[GlottologNames, on = .(Value = ID), nomatch = 0] %>% 
  .[, .(Language_ID, Name)]

colnames(GramFamily) <- c('Lect', 'Family')

GramFamily
```

Make a table of the morphosyntactic distance and the number of shared layers (while also excluding the sign language ``family'', because it's not really a family but rather a modality).
```{r GramGenea}
GramGenea <- GramDistDT %>% 
  .[, Lect := GrambankLects$ID] %>% 
  melt(id.vars = 'Lect',
       variable.name = 'i.Lect',
       value.name = 'Distance') %>% 
  .[, Lect_vs_Lect := str_c(pmin(as.character(Lect), as.character(i.Lect)),
                                'vs.',
                                pmax(as.character(Lect), as.character(i.Lect)),
                               sep = ' ')] %>% 
  .[!duplicated(Lect_vs_Lect)] %>% 
  .[GramFamily, on = .(Lect)] %>% 
  .[GramFamily, on = .(i.Lect = Lect)] %>% 
  .[Family != 'Sign Language' & 
      Family == i.Family & 
      Lect != i.Lect] %>% 
  .[, .(Lect, i.Lect, Family, Distance)] %>% 
  .[SharedLayers, on = .(Lect, i.Lect), nomatch = 0]

GramGenea
```

Subset families of GramGenea to those with at least one layer and at least three lect pairs.
```{r GramGeneaFamilies}
GramGeneaFamilies <-
  GramGenea %>% 
  .[, Max := max(SharedLayers), by = .(Family)] %>% 
  .[Max >= 1] %>% 
  .[, .N, by = .(Family)] %>% 
  .[N >= 3] %>% 
  .[, .(Family)] %>% 
  pull(Family) %>% 
  unique()

GramGeneaFamilies
```

Test the correlation between the morphosyntactic distance and the number of shared layers.
```{r GramGeneaPearson}
GramGeneaPearson <- GramGenea %>% 
  .[Family %in% GramGeneaFamilies] %>% 
  .[, cor.test(Distance, SharedLayers), by = Family] %>% 
  .[, .(Family, parameter, estimate, p.value)] %>% 
  .[!duplicated(.)] %>% 
  .[, parameter := as.integer(parameter + 2)] %>% 
  .[, p.value := p.adjust(p.value)] %>% 
  .[order(estimate)]

colnames(GramGeneaPearson) <- 
 c('Family', 'Number of lect pairs', 'r', 'FDR')

GramGeneaPearson
```
